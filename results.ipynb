{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "results.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nozuaK3_CKjw",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Neuvork/Engeneering-thesis/blob/master/results.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5jcZnINFcRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://<username>:<password>@github.com/Neuvork/Engeneeringthesis.git --single-branch --branch cmaes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQIf2yvLB9pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DOPISAC CMA\n",
        "#ZROBIC REKURENCYJNY ES\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import copy\n",
        "import cupy as cp\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from Engeneeringthesis.sigmas import Sigmas_Neural_Network\n",
        "from Engeneeringthesis.NeuralNetwork import Neural_Network"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl9rVITDlQyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU0va8DSXlK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mempool = cp.get_default_memory_pool()\n",
        "pinned_mempool = cp.get_default_pinned_memory_pool()\n",
        "def cuda_memory_clear():\n",
        "    print(\"_total_bytes_before\", mempool.total_bytes())\n",
        "    mempool.free_all_blocks()\n",
        "    pinned_mempool.free_all_blocks()          \n",
        "    print(\"_total_bytes_after\", mempool.total_bytes())  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGdtEleAayvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_debug = 1\n",
        "basic_debug_mode = 2\n",
        "super_debug_mode = 3\n",
        "only_interesting = 5\n",
        "DEBUG_MODE = only_interesting"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0G2Xf-AR6LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_population():\n",
        "    #300 - liczebnosc populacji\n",
        "    raise exception(\"NEI WOLNO\")\n",
        "    mario_net = Neural_Network([('linear',(300, 28*28, 10))])\n",
        "    mario_net_sigmas = sigmas_Mario_net([('linear',(300, 28*28, 10))])\n",
        "    return (mario_net, mario_net_sigmas)\n",
        "\n",
        "def best_population(population, population_scores, sigmas, population_size = 200000, children_size = 200000):\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"__best_population_start\")\n",
        "    population_size = population.layers[0][1].shape[0]\n",
        "    children_size = population_size\n",
        "    #population.move_to_cpu()\n",
        "    new_marionet = Neural_Network(population.population_size,  population.input_size, population.input_layers)\n",
        "    new_sigmas = Sigmas_Neural_Network(sigmas.sigmas_size,  sigmas.input_size, sigmas.input_layers)\n",
        "    \n",
        "    #new_marionet.move_to_cpu()\n",
        "    for i in range(children_size):\n",
        "        #participants = cp.random.choice( a = population_size, size = 2, replace = False)\n",
        "        #chosen_one = cp.argmax(population_scores[participants])\n",
        "        chosen_one = cp.argmax(population_scores)\n",
        "        new_marionet.replace_individual(i, population.get_individual(chosen_one))\n",
        "        new_sigmas.replace_individual(i, sigmas.get_individual(chosen_one))\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"__best_population_stop\")\n",
        "    return new_marionet, new_sigmas\n",
        "\n",
        "def mutate_sigmas(sigmas, mutation_parameter_individual, mutation_parameter_coordinate):\n",
        "  if DEBUG_MODE % basic_debug_mode == 0:\n",
        "    print(\"SIGMAS MUTATION START\", sigmas.layers_sigmas[0][1].shape)\n",
        "  flag = 0\n",
        "  random_individual_mutation = cp.random.normal(loc = 0., scale = mutation_parameter_individual, size = (sigmas.layers_sigmas[0][1].shape[0], 1, 1, 1, 1))\n",
        "  for layer in sigmas.layers_sigmas:\n",
        "      if layer[0]=='linear' and flag==0:\n",
        "          flag=1\n",
        "          random_individual_mutation = random_individual_mutation.reshape(sigmas.layers_sigmas[0][1].shape[0], 1 ,1)\n",
        "      random_weight_mutation = cp.random.normal(loc = 0., scale = mutation_parameter_coordinate, size = layer[1].shape)\n",
        "      layer[1] *= cp.exp(random_weight_mutation + random_individual_mutation).astype(cp.float32)\n",
        "  if DEBUG_MODE % basic_debug_mode == 0:\n",
        "    print(\"SIGMAS MUTATION STOP\", sigmas.layers_sigmas[0][1].shape)\n",
        "\n",
        "def mutate_network(population, sigmas):\n",
        "  for j in range(len(population.layers)):\n",
        "    population.layers[j][1] += cp.random.normal(0, sigmas.layers_sigmas[j][1], sigmas.layers_sigmas[j][1].shape)\n",
        "\n",
        "\n",
        "def mutate_population(parents, sigmas, mutation_parameter_individual, mutation_parameter_coordinate):\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"__mutate_population_start\")\n",
        "    mutate_sigmas(sigmas, mutation_parameter_individual, mutation_parameter_coordinate)\n",
        "    mutate_network(parents, sigmas)\n",
        "    return parents, sigmas\n",
        "\n",
        "def gen_new_population(population, population_sigmas, children, children_sigmas, population_scores, children_scores):\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"__gen_new_population_start\")\n",
        "    population_size = population.layers[0][1].shape[0]\n",
        "    population_argsorted_scores = cp.argsort(-population_scores)\n",
        "    children_argsorted_scores = cp.argsort(-children_scores)\n",
        "    new_population = Neural_Network(population.population_size,  population.input_size, population.input_layers)\n",
        "    new_sigmas = Sigmas_Neural_Network(population_sigmas.sigmas_size,  population_sigmas.input_size, population_sigmas.input_layers)\n",
        "    \n",
        "\n",
        "    new_scores = cp.zeros(population_size, dtype = cp.float32)\n",
        "\n",
        "    population_pointer = 0 \n",
        "    children_pointer = 0\n",
        "\n",
        "    for i in range(population_size):\n",
        "        if population_scores[population_argsorted_scores[population_pointer]] > children_scores[children_argsorted_scores[children_pointer]]:\n",
        "            new_population.replace_individual(i, population.get_individual(population_argsorted_scores[population_pointer]))\n",
        "            new_sigmas.replace_individual(i, population_sigmas.get_individual(population_argsorted_scores[population_pointer]))\n",
        "            new_scores[i] = population_scores[population_argsorted_scores[population_pointer]]\n",
        "            population_pointer+=1\n",
        "        else:\n",
        "            new_population.replace_individual(i, children.get_individual(children_argsorted_scores[children_pointer]))\n",
        "            new_sigmas.replace_individual(i, children_sigmas.get_individual(children_argsorted_scores[children_pointer]))\n",
        "            new_scores[i] = children_scores[children_argsorted_scores[children_pointer]]\n",
        "            children_pointer+=1    \n",
        "\n",
        "  \n",
        "    #new_population.move_to_gpu()\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"__gen_new_population_stop\")\n",
        "    return new_population, new_sigmas, new_scores\n",
        "\n",
        "def ES(population, sigmas, train_ds, iter_num=2, mutation_parameter_individual=.0001, mutation_parameter_coordinate=.0001):\n",
        "    global best_indivudal_cupy\n",
        "    population_size = population.layers[0][1].shape[0]\n",
        "    children_size = population_size\n",
        "    population_scores = evaluate_population(population, train_ds)\n",
        "    best_results = []\n",
        "    mean_results = []\n",
        "    min_results = []\n",
        "\n",
        "    sigmas_maxes = []\n",
        "    sigmas_mins = []\n",
        "    sigmas_means = []\n",
        "\n",
        "    children_maxes = []\n",
        "    children_mins = []\n",
        "    children_means = []\n",
        "    children_diff_from_best = []\n",
        "\n",
        "\n",
        "    best_results.append(cp.max(population_scores))\n",
        "    mean_results.append(cp.mean(population_scores))\n",
        "    min_results.append(cp.min(population_scores))\n",
        "    \n",
        "    for i in range(iter_num):\n",
        "        parents, parents_sigmas = best_population(population, population_scores, sigmas)\n",
        "        children, children_sigmas = mutate_population(parents, sigmas, mutation_parameter_individual, mutation_parameter_coordinate)\n",
        "        #children.move_to_gpu()\n",
        "        cuda_memory_clear()\n",
        "        children_scores = evaluate_population(children, train_ds)\n",
        "        clear_output()\n",
        "        print(\"BEST CHILDREN RESULT \", cp.max(children_scores))\n",
        "        best_results.append(cp.max(children_scores))\n",
        "        mean_results.append(cp.mean(children_scores))\n",
        "        min_results.append(cp.min(children_scores))\n",
        "\n",
        "        children_maxes.append(cp.max(population.layers[0][1][0]))\n",
        "        children_mins.append(cp.min(population.layers[0][1][0]))\n",
        "        children_means.append(cp.mean(population.layers[0][1][0]))\n",
        "        children_diff_from_best.append(cp.mean(cp.abs(population.layers[0][1][0] - best_indivudal_cupy)))\n",
        "\n",
        "        sigmas_maxes.append(cp.max(sigmas.layers_sigmas[0][1][0]))\n",
        "        sigmas_mins.append(cp.min(sigmas.layers_sigmas[0][1][0]))\n",
        "        sigmas_means.append(cp.mean(sigmas.layers_sigmas[0][1][0]))\n",
        "\n",
        "\n",
        "        fig, axes = plt.subplots(2,2, figsize = (14,10))\n",
        "        axes[0][0].plot(np.array(best_results), color = 'r')\n",
        "        axes[0][0].plot(np.array(mean_results), color = 'g')\n",
        "        axes[0][0].plot(np.array(min_results),  color  = 'b')\n",
        "        axes[0][0].grid(True)\n",
        "        axes[0][0].set_title('Results:')\n",
        "\n",
        "\n",
        "        axes[0][1].plot(np.array(children_maxes), color = 'r')\n",
        "        axes[0][1].plot(np.array(children_mins), color = 'g')\n",
        "        axes[0][1].plot(np.array(children_means),  color  = 'b')\n",
        "        axes[0][0].grid(True)\n",
        "        axes[0][1].set_title('Weights:')\n",
        "\n",
        "        #axes[1][0].plot(np.array(sigmas_maxes), color = 'r')\n",
        "        axes[1][0].plot(np.array(sigmas_mins), color = 'g')\n",
        "        axes[1][0].plot(np.array(sigmas_means),  color  = 'b')\n",
        "        axes[0][0].grid(True)\n",
        "        axes[1][0].set_title(\"Sigmas weights:\")\n",
        "\n",
        "        axes[1][1].plot(np.array(children_diff_from_best), color = 'r')\n",
        "        axes[0][0].grid(True)\n",
        "        axes[1][1].set_title('Distance from classically trained network')\n",
        "        fig.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "\n",
        "        #population.move_to_gpu()\n",
        "        #children.move_to_gpu()\n",
        "        cuda_memory_clear()\n",
        "        population, sigmas, population_scores = gen_new_population(population, sigmas, children, children_sigmas, population_scores, children_scores)\n",
        "        cuda_memory_clear()\n",
        "    return population, sigmas\n",
        "    #return kozak_scores, mean_scores, worst_scores\n",
        "\n",
        "\n",
        "def brute_dot(temp, lin):\n",
        "    ret_temp = cp.zeros((temp.shape[0], lin.shape[2]))\n",
        "    for i in range(temp.shape[0]):\n",
        "        ret_temp[i] = cp.dot(temp[i], lin[i])\n",
        "    return ret_temp\n",
        "\n",
        "\n",
        "def evaluate_population(population, train_ds):\n",
        "    create_input_time = 0\n",
        "    preds_time = 0\n",
        "    points_count_time = 0\n",
        "    j  = 0\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"___EVALUATE_POPULATION_START\")\n",
        "    #scores = np.zeros(population.layers[0][1].shape[0], dtype = np.uint32)\n",
        "    scores = cp.zeros(population.population_size, dtype = cp.uint32)\n",
        "    for image, label in zip(cp.array(train_ds['image']), cp.array(train_ds['label'])):\n",
        "        start = time.time()\n",
        "        image = image.flatten()\n",
        "        create_input_time += time.time() - start\n",
        "        start = time.time()\n",
        "        preds = population.forward(image)\n",
        "        preds_time += time.time() - start\n",
        "        start = time.time()\n",
        "        #scores += cp.asnumpy(preds == label)\n",
        "        scores += preds == label\n",
        "        points_count_time += time.time() - start\n",
        "        j += 1\n",
        "      \n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"___EVALUATE_POPULATION_STOP\", \"create_input_time: \", create_input_time, \"preds_time:\", preds_time,\n",
        "          \"points_count_time: \", points_count_time, \"\\n best result: \", np.max(cp.asnumpy( scores)),\n",
        "          \"mean socre: \", np.mean(cp.asnumpy( scores)), \"min score: \", np.min(cp.asnumpy( scores))) \n",
        "    if DEBUG_MODE % only_interesting == 0:\n",
        "      print(\"best result: \", np.max(cp.asnumpy( scores)), \"mean socre: \", np.mean(cp.asnumpy( scores)), \"min score: \", np.min(cp.asnumpy( scores)))\n",
        "\n",
        "    return scores"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KLahkGJYH2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "POPULATION_SIZE = 5\n",
        "#input size do zmiany\n",
        "population = Neural_Network(POPULATION_SIZE,  (28*28, 1, 1), [['linear', 10, [1.,1.]]])\n",
        "sigmas = Sigmas_Neural_Network(POPULATION_SIZE,  (28*28, 1, 1), [['linear', 10, [1.,1.]]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6SmN-lZSUu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds_mnist = tfds.load(\"mnist\", split = \"train\", shuffle_files=True, batch_size=-1)\n",
        "test_ds_mnist = tfds.load(\"mnist\", split = \"test\", shuffle_files=True, batch_size=-1)\n",
        "\n",
        "train_ds_mnist = tfds.as_numpy(train_ds_mnist)\n",
        "test_ds_mnist = tfds.as_numpy(test_ds_mnist)\n",
        "\n",
        "train_ds_mnist = {\"image\" : cp.array(train_ds_mnist[\"image\"]/255., dtype=cp.float32), \"label\" : cp.array(train_ds_mnist[\"label\"]) }\n",
        "test_ds_mnist = {\"image\" : cp.array(test_ds_mnist[\"image\"]/255., dtype=cp.float32), \"label\" : cp.array(test_ds_mnist[\"label\"]) }"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC4DvHDvSbyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ihPlCYlc4T2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CMA_ES():\n",
        "  def __init__(self,population,sigma,evaluate_func):\n",
        "    self.dimensionality = population.dimensionality\n",
        "    self.covariance_matrix = cp.diag(cp.ones(self.dimensionality, dtype = cp.float32))\n",
        "    print(\"____allocated\")\n",
        "    cuda_memory_clear()\n",
        "    self.population = population\n",
        "    self.sigma = sigma\n",
        "    self.isotropic = cp.zeros(self.dimensionality) #check it\n",
        "    self.anisotropic = cp.zeros(self.dimensionality) #check it\n",
        "    self.evaluate_func = evaluate_func\n",
        "    self.dimensionality = population.dimensionality\n",
        "\n",
        "  def _indicator_function(self, val, alpha):\n",
        "    print(\"___indicator_function start \", val, alpha)\n",
        "    if val < alpha * self.dimensionality and val > 0:\n",
        "      print(\"___indicator_function stop \", 1)\n",
        "      return 1\n",
        "    else:\n",
        "      print(\"___indicator_function stop \", 0)\n",
        "      return 0\n",
        "    return 0\n",
        "\n",
        "\n",
        "  def update_mean(self, scores,sorted_indices,population,mu):\n",
        "    print(\"___update_mean start\")\n",
        "    interesting_values = sorted_indices[:mu]\n",
        "    valuable_individuals = cp.array(self.population.return_chosen_ones(interesting_values)) #maybve works\n",
        "    normalized_interesting_values = interesting_values/cp.sum(interesting_values)\n",
        "    print(\"valuable_individuals.shape \", valuable_individuals.shape)\n",
        "    print(\"normalized_interesting_values.shape \", normalized_interesting_values)\n",
        "    print(\"valuable_individuals: \", valuable_individuals)\n",
        "    print(\"normalized_interesting_values: \", normalized_interesting_values)\n",
        "    updated_mean = cp.mean(valuable_individuals * normalized_interesting_values.reshape(3, 1), axis = 0) #dont know if works\n",
        "    print(\"___update_mean stop\", updated_mean)\n",
        "    return updated_mean\n",
        "  \n",
        "  def calculate_mu_w(self, scores,sorted_indices,mu):\n",
        "    print(\"__calculate_mu_w start\")\n",
        "    interesting_values = sorted_indices[:mu]\n",
        "    interesting_scores = scores[interesting_values]\n",
        "    print(\"__calculate_mu_w stop\")\n",
        "    return 1. / cp.sum(interesting_scores**2)\n",
        "\n",
        "  def update_isotropic(self,mean_act,mean_prev,c_sigma,mu_w):\n",
        "    print(\"__update isotropic start, self.isotropic.shape = \", self.isotropic.shape)\n",
        "    first_term = (1-c_sigma)*self.isotropic\n",
        "    inversed_covariance_matrix = cp.sqrt(cp.linalg.inv(self.covariance_matrix))\n",
        "    second_term = cp.sqrt(1-((1-c_sigma)**2))*cp.sqrt(mu_w)\n",
        "    print(\"mean_act \", mean_act)\n",
        "    print(\"mean_prev \", mean_prev)\n",
        "    print(\"self.sigma \", self.sigma)\n",
        "    third_term = (cp.array(mean_act)-cp.array(mean_prev))/cp.array(self.sigma)\n",
        "    print(\"__update isotropic stop, self.isotropic.shape = \", self.isotropic.shape)\n",
        "    print(\"first term shape: \", first_term.shape)\n",
        "    print(\"inversed_covariance_matrix.shape \", inversed_covariance_matrix.shape)\n",
        "    print(\"second_term.shape \", second_term.shape)\n",
        "    print(\"third_term.shape \", third_term.shape)\n",
        "    print(\"inversed_covariance_matrix*second_term*third_term: \", inversed_covariance_matrix*second_term*third_term.shape)\n",
        "    \n",
        "    return first_term + inversed_covariance_matrix*second_term*third_term\n",
        "  \n",
        "  def compute_cs(self, alpha, c_1, c_covariance):\n",
        "    print(\"__compute_cs start\")\n",
        "    return (1 - self._indicator_function(cp.sqrt(np.sum(self.isotropic ** 2)), alpha)) * c_1 * c_covariance * (2 - c_covariance)\n",
        "    print(\"__compute_cs stop\")\n",
        "\n",
        "  def update_anisotropic(self, mean_act,mean_prev,mu_w,c_covariance,alpha):\n",
        "    print(\"__update_anisotropic start\")\n",
        "    print(\"____ self.isotropic.shape: \", self.isotropic.shape)\n",
        "    ret_val = (1 - c_covariance) * self.anisotropic\n",
        "    ret_val2 = self._indicator_function(self.norm(self.isotropic), alpha)\n",
        "    ret_val2 *= np.sqrt(1 - (1 - c_covariance ** 2))\n",
        "    ret_val2 *= np.sqrt(mu_w)\n",
        "    ret_val2 *= (mean_act - mean_prev) / self.sigma\n",
        "    print(\"__update_anisotropic stop\")\n",
        "    return ret_val + ret_val2\n",
        "  \n",
        "  def _sum_for_covariance_matrix_update(self, scores, sorted_indices, mu, mean_prev): #jakas almbda potrzebna chyba\n",
        "    print(\"___sum_for_covariance_matrix_update start\")\n",
        "    interesting_values = sorted_indices[:mu]\n",
        "    valuable_individuals = cp.array(self.population.return_chosen_ones(interesting_values)) #maybve works\n",
        "    normalized_interesting_values = interesting_values/cp.sum(interesting_values) #wi sequence\n",
        "    ret_sum = .0\n",
        "    for i in range(mu):\n",
        "      ret_sum += normalized_interesting_values[i] * np.dot((valuable_individuals - mean_prev) \n",
        "                / self.sigma, ((valuable_individuals - mean_prev) / self.sigma).T  )\n",
        "    print(\"___sum_for_covariance_matrix_update stop: \", ret_sum)\n",
        "    return ret_sum\n",
        "\n",
        "\n",
        "  def update_covariance_matrix(self, c_1, c_mu, c_s, scores, sorted_indices, mu, mean_prev):\n",
        "    print(\"__update_covariance_matrix start\")\n",
        "    discount_factor = 1 - c_1 - c_mu + c_s\n",
        "    C1 = discount_factor * self.covariance_matrix\n",
        "    C2 = c_1 * np.dot(self.anisotropic, self.anisotropic.T)\n",
        "    C3 = c_s * _sum_for_covariance_matrix_update(scores, sorted_indices, mu)\n",
        "    print(\"__update_covariance_matrix stop\")\n",
        "    return C1 + C2 + C3\n",
        "\n",
        "  def norm(self,vector):\n",
        "    print(\"__norm vector.shape: \", vector.shape)\n",
        "    print(\"___ret val squared: \", vector.dot(vector.T))\n",
        "    print(\"___ret val: \", cp.sqrt(vector.dot(vector.T)))\n",
        "    \n",
        "    return cp.sqrt(vector.dot(vector.T))\n",
        "\n",
        "  def funkcja(self):\n",
        "    return 0\n",
        "\n",
        "  def update_sigma(self,c_sigma,d_sigma):\n",
        "    temp = cp.sqrt(self.dimensionality)*(1-(1/(4*self.dimensionality)) + (1/(21*self.dimensionality**2)))\n",
        "    return self.sigma * cp.exp((c_sigma/d_sigma)*((norm(self.isotropic)/temp)-1))\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "  def fit(self, data, mu, lam, iterations): # mu is how many best samples from population, lam is how much we generate\n",
        "    mean_act = np.zeros(self.dimensionality)\n",
        "    #constant\n",
        "    c_sigma = 3/self.dimensionality\n",
        "    d_sigma = 0.99 #dampening parameter could probably be hyperparameter, wiki says it is close to 1 so whatever\n",
        "    c_covariance = 4/self.dimensionality\n",
        "    alpha = 1.5\n",
        "    c_1 = 2/(self.dimensionality**2)\n",
        "\n",
        "    #body \n",
        "    for i in range(iterations):\n",
        "      self.population.sample(self.covariance_matrix, self.sigma, mean_act, lam) #move it to end of for\n",
        "      self.population.parse_from_vectors() #now we are neuronized\n",
        "      scores = self.evaluate_func(population, data)\n",
        "      sorted_indices = cp.argsort(scores)\n",
        "      mean_prev = mean_act.copy()\n",
        "      #here we want to call self.population.parse_to_vectors()\n",
        "      mean_act = self.update_mean(scores,sorted_indices,population,mu) #we need to be vectorized here\n",
        "      mu_w = self.calculate_mu_w(scores,sorted_indices,mu)\n",
        "      print(\"____self.isotropic.shape: \", self.isotropic.shape)\n",
        "      self.isotropic = self.update_isotropic(mean_act,mean_prev,c_sigma,mu_w)\n",
        "      print(\"____self.isotropic.shape: \", self.isotropic.shape)\n",
        "      c_s = self.compute_cs(alpha,c_1,c_covariance)\n",
        "      print(\"____self.isotropic.shape: \", self.isotropic.shape)\n",
        "      self.anisotropic = self.update_anisotropic(mean_act,mean_prev,mu_w,c_covariance,alpha)\n",
        "      self.covariance_matrix = self.update_covariance_matrix(c_1,mu_w/(self.dimensionality**2),c_s,scores,sorted_indices,mu,mean_prev)\n",
        "      self.sigma = self.update_sigma(c_sigma,d_sigma)\n",
        "    return self.population"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZOmRD_nICsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = CMA_ES(population, 2., evaluate_population)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2dgy2JkII5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit(train_ds_mnist, 3, 5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL86BJ2fLX0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}