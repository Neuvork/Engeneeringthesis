{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "results.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nozuaK3_CKjw"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Neuvork/Engeneering-thesis/blob/master/results.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCs4hqNaNKk1"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKk8gqGsRibt"
      },
      "source": [
        "# This notebook is only example of use of our library to perform evolution on neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQIf2yvLB9pn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from Engeneeringthesis.kernels import *\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import copy\n",
        "import cupy as cp\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from Engeneeringthesis.NeuralNetwork import Neural_Network\n",
        "from Engeneeringthesis.Cma_es import CMA_ES\n",
        "from Engeneeringthesis.Caged_CMA_ES import Caged_CMA_ES\n",
        "from Engeneeringthesis.Logs import Logs\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU0va8DSXlK5"
      },
      "source": [
        "mempool = cp.get_default_memory_pool()\n",
        "pinned_mempool = cp.get_default_pinned_memory_pool()\n",
        "def cuda_memory_clear():\n",
        "    mempool.free_all_blocks()\n",
        "    pinned_mempool.free_all_blocks()          "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk4blBpGJmhK"
      },
      "source": [
        "## Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiPNoAcKJjU1"
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'cifar10',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "\n",
        "def normalize_img(image, label):\n",
        "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
        "  return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(32)\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(\n",
        "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "ds_test = ds_test.batch(32)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q_rCLbdLaPM",
        "outputId": "7d5ec1ef-31d3-4937-b64c-af8fe2ba6a7f"
      },
      "source": [
        "#ensuring that algorithm won't see any images that tensorflow haven't seen\n",
        "TRAINING_SIZE = 0 #global value for division in evaluate function\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for batch in ds_train:\n",
        "  for image, label in zip(batch[0], batch[1]):\n",
        "    #for rgb images:\n",
        "    temp = image.numpy().copy()\n",
        "    image = image.numpy().reshape(image.shape[2], image.shape[0], image.shape[1])\n",
        "    if image.shape[0] == 3:\n",
        "      image[0, :, :] = temp[:,:,0]\n",
        "      image[1, :, :] = temp[:,:,1]\n",
        "      image[2, :, :] = temp[:,:,2]\n",
        "    images.append(cp.array(image, dtype =cp.float32))\n",
        "    labels.append(label)\n",
        "    TRAINING_SIZE += 1\n",
        "\n",
        "for batch in ds_test:\n",
        "  for image, label in zip(batch[0], batch[1]):\n",
        "    #for rgb images:\n",
        "    temp = image.numpy().copy()\n",
        "    image = image.numpy().reshape(image.shape[2], image.shape[0], image.shape[1])\n",
        "    if image.shape[0] == 3:\n",
        "      image[0, :, :] = temp[:,:,0]\n",
        "      image[1, :, :] = temp[:,:,1]\n",
        "      image[2, :, :] = temp[:,:,2]\n",
        "    images.append(cp.array(image, dtype =cp.float32))\n",
        "    labels.append(label)\n",
        "images = cp.array(images, dtype = cp.float32)\n",
        "labesl = cp.array(labels)\n",
        "print(images.shape)\n",
        "train_ds_mnist = {\"image\" : images, \"label\" : labels }"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 3, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsU0WaHo_Q7g"
      },
      "source": [
        "## Training network with TensorFlow\n",
        "Of course there is no need to pretrain network, epecially when evaluate function cannot be derivated it is impoosible to perform previous training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jr2RJuS0Ilg"
      },
      "source": [
        "model = tf.keras.models.Sequential([                    \n",
        "  tf.keras.layers.Conv2D(filters= 4, kernel_size = 3, activation='tanh', use_bias=False),\n",
        "  tf.keras.layers.MaxPool2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10, use_bias=False)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.0008),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=20,\n",
        "    validation_data=ds_train,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvXdRlTPLRV7"
      },
      "source": [
        "## Alocating population\n",
        "We tested our algorithm on network with no bias after convolutional layer and with structirue of:\n",
        "\n",
        "\n",
        "\n",
        "1.   Convolutional layer with 4 filters\n",
        "2.   Dense layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dapKXAOa8gj9"
      },
      "source": [
        "POPULATION_SIZE = 2048\n",
        "input_size = train_ds_mnist['image'][0].shape\n",
        "population = Neural_Network(POPULATION_SIZE,  input_size, \n",
        "                            [\n",
        "                             ['conv', (4, 3, 3), [1.,1.]],\n",
        "                             ['linear', 10, [1.,1.]]\n",
        "                             ],\n",
        "                             use_bias=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieJK8l9LEOrS"
      },
      "source": [
        "## Measure of individuals in population for algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBsR5kwYEQOO"
      },
      "source": [
        "def evaluate_population(population, train_ds):\n",
        "    global TRAINING_SIZE\n",
        "    create_input_time = 0\n",
        "    preds_time = 0\n",
        "    points_count_time = 0\n",
        "    j  = 0\n",
        "    train_dataset = {'image' : train_ds['image'][:TRAINING_SIZE],\n",
        "                      'label' : train_ds['label'][:TRAINING_SIZE] }\n",
        "    validation_dataset = {'image' : train_ds['image'][TRAINING_SIZE:],\n",
        "                      'label' : train_ds['label'][TRAINING_SIZE:] }\n",
        "    train_scores = cp.zeros(population.population_size, dtype = cp.uint32)\n",
        "    for image, label in zip(cp.array(train_dataset['image']), cp.array(train_dataset['label'])):\n",
        "        start = time.time()\n",
        "        create_input_time += time.time() - start\n",
        "        start = time.time()\n",
        "        preds = population.forward(image)\n",
        "        preds_time += time.time() - start\n",
        "        start = time.time()\n",
        "        train_scores += preds == label\n",
        "        points_count_time += time.time() - start\n",
        "        j += 1\n",
        "\n",
        "    validation_scores = cp.zeros(population.population_size, dtype = cp.uint32)\n",
        "    for image, label in zip(cp.array(validation_dataset['image']), cp.array(validation_dataset['label'])):\n",
        "        start = time.time()\n",
        "        create_input_time += time.time() - start\n",
        "        start = time.time()\n",
        "        preds = population.forward(image)\n",
        "        preds_time += time.time() - start\n",
        "        start = time.time()\n",
        "        validation_scores += preds == label\n",
        "        points_count_time += time.time() - start\n",
        "        j += 1\n",
        "      \n",
        "\n",
        "    return train_scores/len(train_dataset['image']), validation_scores/len(validation_dataset['image'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAPb2DkP_5aK"
      },
      "source": [
        "# Parsers of layers from TensorFlow to population\n",
        " Due to differences in implenetation of convolutional layers we needed to implement methods that will transfer layers from one object to antoher, for tests we used only one convolutional layer with 4 filters and dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKbhkB2s2Ozy"
      },
      "source": [
        "def copy_conv_layer(model_layer_num, population_layer_num, individual_num=0):\n",
        "  global model\n",
        "  global population\n",
        "  model_layer = model.layers[model_layer_num].weights[0]\n",
        "  for output_filter_number in range(population.layers[population_layer_num][1].shape[1]):\n",
        "    for input_filter_number in range(population.layers[population_layer_num][1].shape[2]):\n",
        "      population.layers[population_layer_num][1][individual_num, output_filter_number, input_filter_number, :, :] = cp.array(model_layer[:, :, input_filter_number, output_filter_number].numpy(), dtype=cp.float32)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hvLcA2864-6"
      },
      "source": [
        "def inv(perm):\n",
        "    inverse = [0] * len(perm)\n",
        "    for i, p in enumerate(perm):\n",
        "        inverse[p] = i\n",
        "    return inverse\n",
        "\n",
        "\n",
        "def copy_linear_layer(model_layer_num, population_layer_num, individual_num=0):\n",
        "  global model\n",
        "  global population\n",
        "  model_layer = model.layers[model_layer_num].weights[0].numpy()\n",
        "  xd_layer = cp.zeros(shape=model_layer.shape, dtype = cp.float32)\n",
        "  prev_shape = population.input_sizes[population_layer_num -1]\n",
        "  s1 = prev_shape[2]\n",
        "  s2 = prev_shape[3]\n",
        "  permutacja = np.zeros(shape = (xd_layer.shape[0]), dtype = np.int32)\n",
        "  for i in range(prev_shape[1]): \n",
        "    for j in range(prev_shape[2]): \n",
        "      for k in range(prev_shape[3]): \n",
        "        permutacja[j * prev_shape[2] * prev_shape[1] + k * prev_shape[1] + i] = i*s1*s2 + j*s2 + k\n",
        "\n",
        "\n",
        "  inverted = inv(permutacja)\n",
        "  for i in range(len(inverted)):\n",
        "    xd_layer[i,:] = cp.array(model_layer[inverted[i], :], dtype=cp.float32)\n",
        "\n",
        "  population.layers[population_layer_num][1][individual_num] = xd_layer "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKcefh7KEm2B"
      },
      "source": [
        "for i in range(20):\n",
        "  copy_conv_layer(0, 0, i)\n",
        "  copy_linear_layer(3, 2, i)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fr56M2lAS5n"
      },
      "source": [
        "## Ensuring that results in both models are the same (test of parsers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXqdmXwhvF8G"
      },
      "source": [
        "model.evaluate(\n",
        "    ds_train\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVT810GJvbKl"
      },
      "source": [
        "population_score = evaluate_population(population,train_ds_mnist)\n",
        "cp.max(population_score[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFFqDZU2Q7F_"
      },
      "source": [
        "logs = Logs([('matrix','covariance'),('population', 'population'),('number','sigma'),\n",
        "                      ('vector','isotropic'),('vector','anisotropic'),('vector','mean'),\n",
        "                      ('number','best-train-score'), ('number','best-validation-score'),\n",
        "                       ('vector', 'mean_act - mena_prev')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW0GxRCgAZxf"
      },
      "source": [
        "## Racing with Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF8NUXjXIeOy"
      },
      "source": [
        "classifier = CMA_ES(population, .01, evaluate_population, logs, hp_loops_number=4)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GX4CLDUmQ-r-"
      },
      "source": [
        "classifier.fit(train_ds_mnist, POPULATION_SIZE//64, POPULATION_SIZE, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znWvCTz-Reht"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}