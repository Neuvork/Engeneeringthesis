{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "results.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nozuaK3_CKjw"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Neuvork/Engeneering-thesis/blob/master/results.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5jcZnINFcRT"
      },
      "source": [
        "! git clone https://<username>:<password>@github.com/Neuvork/Engeneeringthesis.git --single-branch --branch cmaes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQIf2yvLB9pn"
      },
      "source": [
        "#DOPISAC CMA\n",
        "#ZROBIC REKURENCYJNY ES\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.linalg import sqrtm\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import copy\n",
        "import cupy as cp\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from Engeneeringthesis.sigmas import Sigmas_Neural_Network\n",
        "from Engeneeringthesis.NeuralNetwork import Neural_Network"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl9rVITDlQyH"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU0va8DSXlK5"
      },
      "source": [
        "mempool = cp.get_default_memory_pool()\n",
        "pinned_mempool = cp.get_default_pinned_memory_pool()\n",
        "def cuda_memory_clear():\n",
        "    print(\"_total_bytes_before\", mempool.total_bytes())\n",
        "    mempool.free_all_blocks()\n",
        "    pinned_mempool.free_all_blocks()          \n",
        "    print(\"_total_bytes_after\", mempool.total_bytes())  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGdtEleAayvp"
      },
      "source": [
        "no_debug = 1\n",
        "basic_debug_mode = 2\n",
        "super_debug_mode = 3\n",
        "only_interesting = 5\n",
        "DEBUG_MODE = only_interesting"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0G2Xf-AR6LJ"
      },
      "source": [
        "def generate_population():\n",
        "    #300 - liczebnosc populacji\n",
        "    raise exception(\"NEI WOLNO\")\n",
        "    mario_net = Neural_Network([('linear',(300, 28*28, 10))])\n",
        "    mario_net_sigmas = sigmas_Mario_net([('linear',(300, 28*28, 10))])\n",
        "    return (mario_net, mario_net_sigmas)\n",
        "\n",
        "def best_population(population, population_scores, sigmas, population_size = 200000, children_size = 200000):\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"__best_population_start\")\n",
        "    population_size = population.layers[0][1].shape[0]\n",
        "    children_size = population_size\n",
        "    #population.move_to_cpu()\n",
        "    new_marionet = Neural_Network(population.population_size,  population.input_size, population.input_layers)\n",
        "    new_sigmas = Sigmas_Neural_Network(sigmas.sigmas_size,  sigmas.input_size, sigmas.input_layers)\n",
        "    \n",
        "    #new_marionet.move_to_cpu()\n",
        "    for i in range(children_size):\n",
        "        #participants = cp.random.choice( a = population_size, size = 2, replace = False)\n",
        "        #chosen_one = cp.argmax(population_scores[participants])\n",
        "        chosen_one = cp.argmax(population_scores)\n",
        "        new_marionet.replace_individual(i, population.get_individual(chosen_one))\n",
        "        new_sigmas.replace_individual(i, sigmas.get_individual(chosen_one))\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"__best_population_stop\")\n",
        "    return new_marionet, new_sigmas\n",
        "\n",
        "def mutate_sigmas(sigmas, mutation_parameter_individual, mutation_parameter_coordinate):\n",
        "  if DEBUG_MODE % basic_debug_mode == 0:\n",
        "    print(\"SIGMAS MUTATION START\", sigmas.layers_sigmas[0][1].shape)\n",
        "  flag = 0\n",
        "  random_individual_mutation = cp.random.normal(loc = 0., scale = mutation_parameter_individual, size = (sigmas.layers_sigmas[0][1].shape[0], 1, 1, 1, 1))\n",
        "  for layer in sigmas.layers_sigmas:\n",
        "      if layer[0]=='linear' and flag==0:\n",
        "          flag=1\n",
        "          random_individual_mutation = random_individual_mutation.reshape(sigmas.layers_sigmas[0][1].shape[0], 1 ,1)\n",
        "      random_weight_mutation = cp.random.normal(loc = 0., scale = mutation_parameter_coordinate, size = layer[1].shape)\n",
        "      layer[1] *= cp.exp(random_weight_mutation + random_individual_mutation).astype(cp.float32)\n",
        "  if DEBUG_MODE % basic_debug_mode == 0:\n",
        "    print(\"SIGMAS MUTATION STOP\", sigmas.layers_sigmas[0][1].shape)\n",
        "\n",
        "def mutate_network(population, sigmas):\n",
        "  for j in range(len(population.layers)):\n",
        "    population.layers[j][1] += cp.random.normal(0, sigmas.layers_sigmas[j][1], sigmas.layers_sigmas[j][1].shape)\n",
        "\n",
        "\n",
        "def mutate_population(parents, sigmas, mutation_parameter_individual, mutation_parameter_coordinate):\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"__mutate_population_start\")\n",
        "    mutate_sigmas(sigmas, mutation_parameter_individual, mutation_parameter_coordinate)\n",
        "    mutate_network(parents, sigmas)\n",
        "    return parents, sigmas\n",
        "\n",
        "def gen_new_population(population, population_sigmas, children, children_sigmas, population_scores, children_scores):\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"__gen_new_population_start\")\n",
        "    population_size = population.layers[0][1].shape[0]\n",
        "    population_argsorted_scores = cp.argsort(-population_scores)\n",
        "    children_argsorted_scores = cp.argsort(-children_scores)\n",
        "    new_population = Neural_Network(population.population_size,  population.input_size, population.input_layers)\n",
        "    new_sigmas = Sigmas_Neural_Network(population_sigmas.sigmas_size,  population_sigmas.input_size, population_sigmas.input_layers)\n",
        "    \n",
        "\n",
        "    new_scores = cp.zeros(population_size, dtype = cp.float32)\n",
        "\n",
        "    population_pointer = 0 \n",
        "    children_pointer = 0\n",
        "\n",
        "    for i in range(population_size):\n",
        "        if population_scores[population_argsorted_scores[population_pointer]] > children_scores[children_argsorted_scores[children_pointer]]:\n",
        "            new_population.replace_individual(i, population.get_individual(population_argsorted_scores[population_pointer]))\n",
        "            new_sigmas.replace_individual(i, population_sigmas.get_individual(population_argsorted_scores[population_pointer]))\n",
        "            new_scores[i] = population_scores[population_argsorted_scores[population_pointer]]\n",
        "            population_pointer+=1\n",
        "        else:\n",
        "            new_population.replace_individual(i, children.get_individual(children_argsorted_scores[children_pointer]))\n",
        "            new_sigmas.replace_individual(i, children_sigmas.get_individual(children_argsorted_scores[children_pointer]))\n",
        "            new_scores[i] = children_scores[children_argsorted_scores[children_pointer]]\n",
        "            children_pointer+=1    \n",
        "\n",
        "  \n",
        "    #new_population.move_to_gpu()\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"__gen_new_population_stop\")\n",
        "    return new_population, new_sigmas, new_scores\n",
        "\n",
        "def ES(population, sigmas, train_ds, iter_num=2, mutation_parameter_individual=.0001, mutation_parameter_coordinate=.0001):\n",
        "    global best_indivudal_cupy\n",
        "    population_size = population.layers[0][1].shape[0]\n",
        "    children_size = population_size\n",
        "    population_scores = evaluate_population(population, train_ds)\n",
        "    best_results = []\n",
        "    mean_results = []\n",
        "    min_results = []\n",
        "\n",
        "    sigmas_maxes = []\n",
        "    sigmas_mins = []\n",
        "    sigmas_means = []\n",
        "\n",
        "    children_maxes = []\n",
        "    children_mins = []\n",
        "    children_means = []\n",
        "    children_diff_from_best = []\n",
        "\n",
        "\n",
        "    best_results.append(cp.max(population_scores))\n",
        "    mean_results.append(cp.mean(population_scores))\n",
        "    min_results.append(cp.min(population_scores))\n",
        "    \n",
        "    for i in range(iter_num):\n",
        "        parents, parents_sigmas = best_population(population, population_scores, sigmas)\n",
        "        children, children_sigmas = mutate_population(parents, sigmas, mutation_parameter_individual, mutation_parameter_coordinate)\n",
        "        #children.move_to_gpu()\n",
        "        cuda_memory_clear()\n",
        "        children_scores = evaluate_population(children, train_ds)\n",
        "        clear_output()\n",
        "        print(\"BEST CHILDREN RESULT \", cp.max(children_scores))\n",
        "        best_results.append(cp.max(children_scores))\n",
        "        mean_results.append(cp.mean(children_scores))\n",
        "        min_results.append(cp.min(children_scores))\n",
        "\n",
        "        children_maxes.append(cp.max(population.layers[0][1][0]))\n",
        "        children_mins.append(cp.min(population.layers[0][1][0]))\n",
        "        children_means.append(cp.mean(population.layers[0][1][0]))\n",
        "        children_diff_from_best.append(cp.mean(cp.abs(population.layers[0][1][0] - best_indivudal_cupy)))\n",
        "\n",
        "        sigmas_maxes.append(cp.max(sigmas.layers_sigmas[0][1][0]))\n",
        "        sigmas_mins.append(cp.min(sigmas.layers_sigmas[0][1][0]))\n",
        "        sigmas_means.append(cp.mean(sigmas.layers_sigmas[0][1][0]))\n",
        "\n",
        "\n",
        "        fig, axes = plt.subplots(2,2, figsize = (14,10))\n",
        "        axes[0][0].plot(np.array(best_results), color = 'r')\n",
        "        axes[0][0].plot(np.array(mean_results), color = 'g')\n",
        "        axes[0][0].plot(np.array(min_results),  color  = 'b')\n",
        "        axes[0][0].grid(True)\n",
        "        axes[0][0].set_title('Results:')\n",
        "\n",
        "\n",
        "        axes[0][1].plot(np.array(children_maxes), color = 'r')\n",
        "        axes[0][1].plot(np.array(children_mins), color = 'g')\n",
        "        axes[0][1].plot(np.array(children_means),  color  = 'b')\n",
        "        axes[0][0].grid(True)\n",
        "        axes[0][1].set_title('Weights:')\n",
        "\n",
        "        #axes[1][0].plot(np.array(sigmas_maxes), color = 'r')\n",
        "        axes[1][0].plot(np.array(sigmas_mins), color = 'g')\n",
        "        axes[1][0].plot(np.array(sigmas_means),  color  = 'b')\n",
        "        axes[0][0].grid(True)\n",
        "        axes[1][0].set_title(\"Sigmas weights:\")\n",
        "\n",
        "        axes[1][1].plot(np.array(children_diff_from_best), color = 'r')\n",
        "        axes[0][0].grid(True)\n",
        "        axes[1][1].set_title('Distance from classically trained network')\n",
        "        fig.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "\n",
        "        #population.move_to_gpu()\n",
        "        #children.move_to_gpu()\n",
        "        cuda_memory_clear()\n",
        "        population, sigmas, population_scores = gen_new_population(population, sigmas, children, children_sigmas, population_scores, children_scores)\n",
        "        cuda_memory_clear()\n",
        "    return population, sigmas\n",
        "    #return kozak_scores, mean_scores, worst_scores\n",
        "\n",
        "\n",
        "def brute_dot(temp, lin):\n",
        "    ret_temp = cp.zeros((temp.shape[0], lin.shape[2]))\n",
        "    for i in range(temp.shape[0]):\n",
        "        ret_temp[i] = cp.dot(temp[i], lin[i])\n",
        "    return ret_temp\n",
        "\n",
        "\n",
        "def evaluate_population(population, train_ds):\n",
        "    create_input_time = 0\n",
        "    preds_time = 0\n",
        "    points_count_time = 0\n",
        "    j  = 0\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"___EVALUATE_POPULATION_START\")\n",
        "    #scores = np.zeros(population.layers[0][1].shape[0], dtype = np.uint32)\n",
        "    scores = cp.zeros(population.population_size, dtype = cp.uint32)\n",
        "    for image, label in zip(cp.array(train_ds['image']), cp.array(train_ds['label'])):\n",
        "        start = time.time()\n",
        "        image = image.flatten()\n",
        "        create_input_time += time.time() - start\n",
        "        start = time.time()\n",
        "        preds = population.forward(image)\n",
        "        preds_time += time.time() - start\n",
        "        start = time.time()\n",
        "        #scores += cp.asnumpy(preds == label)\n",
        "        scores += preds == label\n",
        "        points_count_time += time.time() - start\n",
        "        j += 1\n",
        "      \n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"___EVALUATE_POPULATION_STOP\", \"create_input_time: \", create_input_time, \"preds_time:\", preds_time,\n",
        "          \"points_count_time: \", points_count_time, \"\\n best result: \", np.max(cp.asnumpy( scores)),\n",
        "          \"mean socre: \", np.mean(cp.asnumpy( scores)), \"min score: \", np.min(cp.asnumpy( scores))) \n",
        "    if DEBUG_MODE % only_interesting == 0:\n",
        "      print(\"best result: \", np.max(cp.asnumpy( scores)), \"mean socre: \", np.mean(cp.asnumpy( scores)), \"min score: \", np.min(cp.asnumpy( scores)))\n",
        "\n",
        "    return scores"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KLahkGJYH2S"
      },
      "source": [
        "POPULATION_SIZE = 5\n",
        "#input size do zmiany\n",
        "population = Neural_Network(POPULATION_SIZE,  (28*28, 1, 1), [['linear', 10, [1.,1.]]])\n",
        "sigmas = Sigmas_Neural_Network(POPULATION_SIZE,  (28*28, 1, 1), [['linear', 10, [1.,1.]]])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6SmN-lZSUu_"
      },
      "source": [
        "train_ds_mnist = tfds.load(\"mnist\", split = \"train\", shuffle_files=True, batch_size=-1)\n",
        "test_ds_mnist = tfds.load(\"mnist\", split = \"test\", shuffle_files=True, batch_size=-1)\n",
        "\n",
        "train_ds_mnist = tfds.as_numpy(train_ds_mnist)\n",
        "test_ds_mnist = tfds.as_numpy(test_ds_mnist)\n",
        "\n",
        "train_ds_mnist = {\"image\" : cp.array(train_ds_mnist[\"image\"]/255., dtype=cp.float32), \"label\" : cp.array(train_ds_mnist[\"label\"]) }\n",
        "test_ds_mnist = {\"image\" : cp.array(test_ds_mnist[\"image\"]/255., dtype=cp.float32), \"label\" : cp.array(test_ds_mnist[\"label\"]) }"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC4DvHDvSbyJ"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ihPlCYlc4T2"
      },
      "source": [
        "class CMA_ES():\n",
        "  def __init__(self,population,sigma,evaluate_func):\n",
        "    self.dimensionality = population.dimensionality\n",
        "    self.covariance_matrix = cp.diag(cp.ones(self.dimensionality, dtype = cp.float32))\n",
        "    print(\"____allocated\")\n",
        "    cuda_memory_clear()\n",
        "    self.population = population\n",
        "    self.sigma = sigma\n",
        "    self.isotropic = cp.zeros(self.dimensionality) #check it\n",
        "    self.anisotropic = cp.zeros(self.dimensionality) #check it\n",
        "    self.evaluate_func = evaluate_func\n",
        "    self.dimensionality = population.dimensionality\n",
        "    self.weights = 0 #0 is just placeholder\n",
        "    self.logs = Logs([('matrix','covariance'),('population','population'),('number','sigma'),\n",
        "                      ('vector','isotropic'),('vector','anisotropic'),('vector','mean'),\n",
        "                      ('number','best-score'),['vector','mean diff']])\n",
        "\n",
        "  def _indicator_function(self, val, alpha):\n",
        "    print(\"___indicator_function start \", val, alpha)\n",
        "    if val < alpha * self.dimensionality and val > 0:\n",
        "      print(\"___indicator_function stop \", 1)\n",
        "      return 1\n",
        "    else:\n",
        "      print(\"___indicator_function stop \", 0)\n",
        "      return 0\n",
        "    return 0\n",
        "\n",
        "\n",
        "  def update_mean(self, scores,sorted_indices,population,mu):\n",
        "    print(\"___update_mean start\")\n",
        "    interesting_values = sorted_indices[:mu]\n",
        "    valuable_individuals = cp.array(self.population.return_chosen_ones(interesting_values))\n",
        "    print(\"valuable_individuals.shape \", valuable_individuals.shape)\n",
        "    print(\"normalized_interesting_values \", self.weights)\n",
        "    print(\"valuable_individuals: \", valuable_individuals)\n",
        "    updated_mean = np.sum(valuable_individuals * self.weights.reshape(-1,1),axis = 0)\n",
        "    print(\"___update_mean stop\", updated_mean)\n",
        "    return updated_mean\n",
        "\n",
        "  def update_isotropic(self,mean_act,mean_prev,c_sigma,mu_w):\n",
        "    print(\"__update isotropic start, self.isotropic.shape = \", self.isotropic.shape)\n",
        "    first_term = (1-c_sigma)*self.isotropic\n",
        "    #q,r = cp.linalg.qr(self.covariance_matrix)\n",
        "    #inversed_covariance_matrix = cp.linalg.inv(r).dot(q.T)\n",
        "    #inversed_covariance_matrix = cp.real(cp.array(sqrtm(cp.asnumpy(cp.linalg.inv(self.covariance_matrix)))))\n",
        "    inversed_covariance_matrix = cp.linalg.cholesky(cp.linalg.inv(self.covariance_matrix))\n",
        "    test = inversed_covariance_matrix.dot(inversed_covariance_matrix)\n",
        "    inv_test = cp.linalg.inv(self.covariance_matrix)\n",
        "    print(\"__difference without imaginary: \",cp.max(test-inv_test),cp.mean((test-inv_test).flatten()),cp.min(test-inv_test))\n",
        "    second_term = cp.sqrt(1-((1-c_sigma)**2))*cp.sqrt(mu_w)\n",
        "    print(\"mean_act \", mean_act)\n",
        "    print(\"mean_prev \", mean_prev)\n",
        "    print(\"self.sigma \", self.sigma)\n",
        "    third_term = (cp.array(mean_act)-cp.array(mean_prev))/cp.array(self.sigma)\n",
        "    print(\"__update isotropic stop, self.isotropic.shape = \", self.isotropic.shape)\n",
        "    print(\"first term shape: \", first_term.shape)\n",
        "    print(\"inversed_covariance_matrix.shape \", inversed_covariance_matrix.shape)\n",
        "    print(\"second_term.shape \", second_term.shape)\n",
        "    print(\"third_term.shape \", third_term.shape)\n",
        "    print(\"inversed_covariance_matrix*second_term*third_term: \", (second_term*inversed_covariance_matrix.dot(third_term)))\n",
        "    print(\"__first_term\",first_term)\n",
        "    print(\"second_term\",second_term)\n",
        "    print(\"third_term\",third_term)\n",
        "    print(\"mult_result\",inversed_covariance_matrix.dot(third_term))\n",
        "    print(\"inversed_covariance_matrix\",inversed_covariance_matrix)\n",
        "    return first_term + second_term*inversed_covariance_matrix.dot(third_term)\n",
        "  \n",
        "  def compute_cs(self, alpha, c_1, c_covariance):\n",
        "    print(\"__compute_cs start\")\n",
        "    print(\"__compute_cs end\")\n",
        "    return (1 - self._indicator_function(cp.sqrt(cp.sum(self.isotropic ** 2)), alpha)) * c_1 * c_covariance * (2 - c_covariance)\n",
        "\n",
        "  def update_anisotropic(self, mean_act,mean_prev,mu_w,c_covariance,alpha):\n",
        "    print(\"__update_anisotropic start\")\n",
        "    print(\"____ self.isotropic.shape: \", self.isotropic.shape)\n",
        "    ret_val = (1 - c_covariance) * self.anisotropic\n",
        "    ret_val2 = self._indicator_function(self.norm(self.isotropic), alpha)\n",
        "    ret_val2 *= np.sqrt(1 - (1 - c_covariance ** 2))\n",
        "    ret_val2 *= np.sqrt(mu_w)\n",
        "    ret_val3 = (mean_act - mean_prev) / self.sigma\n",
        "    print(\"__update_anisotropic stop\")\n",
        "    return ret_val + ret_val2 * ret_val3\n",
        "  \n",
        "  def _sum_for_covariance_matrix_update(self, scores, sorted_indices, mu, mean_prev): #jakas almbda potrzebna chyba\n",
        "    print(\"___sum_for_covariance_matrix_update start\")\n",
        "    interesting_values = sorted_indices[:mu]\n",
        "    valuable_individuals = cp.array(self.population.return_chosen_ones(interesting_values)) \n",
        "    ret_sum = .0\n",
        "    for i in range(mu):\n",
        "      ret_sum += self.weights[i] * np.dot((valuable_individuals[i] - mean_prev).reshape(-1,1) #result should be matrix!!!\n",
        "                / self.sigma, ((valuable_individuals[i] - mean_prev).reshape(1,-1) / self.sigma)  )\n",
        "    print(\"___sum_for_covariance_matrix_update stop: \", ret_sum)\n",
        "    return ret_sum\n",
        "\n",
        "\n",
        "  def update_covariance_matrix(self, c_1, c_mu, c_s, scores, sorted_indices, mu, mean_prev):\n",
        "    print(\"__update_covariance_matrix start\")\n",
        "    print(\"__covariance matrix\",self.covariance_matrix)\n",
        "    print(\"_______\")\n",
        "    print(\"_______\")\n",
        "    print(\"_______\")\n",
        "    discount_factor = 1 - c_1 - c_mu + c_s\n",
        "    C1 = discount_factor * self.covariance_matrix\n",
        "    C2 = c_1 * (self.anisotropic.reshape(-1,1).dot(self.anisotropic.reshape(1,-1)))\n",
        "    C25 = self._sum_for_covariance_matrix_update(scores, sorted_indices, mu, mean_prev)\n",
        "    C3 = c_mu * self._sum_for_covariance_matrix_update(scores, sorted_indices, mu, mean_prev)\n",
        "    print(\"__shapeOfALL\",C1.shape,C2.shape,C3.shape,C25.shape)\n",
        "    print(\"__update_covariance_matrix stop\")\n",
        "    return C1 + C2 + C3\n",
        "\n",
        "  def norm(self,vector):\n",
        "    print(\"__norm vector.shape: \", vector.shape)\n",
        "    print(\"__norm vector: \", vector)\n",
        "    print(\"___ret val squared: \", vector.dot(vector.T))\n",
        "    print(\"___ret val: \", cp.sqrt(vector.dot(vector.T)))\n",
        "    \n",
        "    return cp.sqrt(vector.dot(vector.T))\n",
        "\n",
        "  def update_sigma(self,c_sigma,d_sigma):\n",
        "    print(\"_update_sigma start\")\n",
        "    temp = cp.sqrt(self.dimensionality)*(1-(1/(4*self.dimensionality)) + (1/(21*self.dimensionality**2)))\n",
        "    temp2 = cp.exp((c_sigma/d_sigma)*((self.norm(self.isotropic)/temp)-1))\n",
        "    print(\"_update_sigma stop\")\n",
        "    return self.sigma * temp2\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "  def fit(self, data, mu, lam, iterations): # mu is how many best samples from population, lam is how much we generate\n",
        "    mean_act = cp.zeros(self.dimensionality)\n",
        "    #constant\n",
        "    self.weights = cp.log(mu+1/2) - cp.log(cp.arange(1,mu+1))\n",
        "    self.weights = self.weights/cp.sum(self.weights)\n",
        "    mu_w = 1/cp.sum(self.weights**2)\n",
        "\n",
        "    c_sigma = (mu_w + 2)/(self.dimensionality + mu_w + 5)\n",
        "    d_sigma = 1 + 2*max([0,cp.sqrt((mu_w - 1)/(self.dimensionality + 1)) - 1]) + c_sigma #dampening parameter could probably be hyperparameter, wiki says it is close to 1 so whatever\n",
        "    c_covariance = (4 + mu_w/self.dimensionality)/(self.dimensionality + 4 + 2*mu_w/self.dimensionality) # c_covariance * 100 not working\n",
        "    c_1 = 2/(self.dimensionality**2)\n",
        "    c_mu = min([1-c_1,2*(mu_w - 2 + 1/mu_w)/(((self.dimensionality+2)**2)+mu_w)])\n",
        "    alpha = 1.5\n",
        "    #body \n",
        "    for i in range(iterations):\n",
        "      scores = self.evaluate_func(population, data)\n",
        "      print(cp.max(scores))\n",
        "      sorted_indices = cp.argsort(-scores)\n",
        "      mean_prev = mean_act.copy()\n",
        "      self.population.parse_to_vector()\n",
        "      mean_act = self.update_mean(scores,sorted_indices,population,mu) #we need to be vectorized here\n",
        "      self.logs.log([self.covariance_matrix,self.population.matrix,self.sigma,self.isotropic,self.anisotropic,mean_prev,cp.max(scores),mean_act-mean_prev])\n",
        "      self.logs.plot()\n",
        "      print(\"____self.isotropic.shape: \", self.isotropic.shape)\n",
        "      self.isotropic = self.update_isotropic(mean_act,mean_prev,c_sigma,mu_w)\n",
        "      print(\"____self.isotropic.shape: \", self.isotropic.shape)\n",
        "      c_s = self.compute_cs(alpha,c_1,c_covariance)\n",
        "      print(\"____self.isotropic.shape: \", self.isotropic.shape)\n",
        "      self.anisotropic = self.update_anisotropic(mean_act,mean_prev,mu_w,c_covariance,alpha)\n",
        "      self.covariance_matrix = self.update_covariance_matrix(c_1,c_mu,c_s,scores,sorted_indices,mu,mean_prev)\n",
        "      self.sigma = self.update_sigma(c_sigma,d_sigma)\n",
        "      self.population.sample(self.covariance_matrix, self.sigma, mean_act, lam)\n",
        "      self.population.parse_from_vectors()\n",
        "    return self.population"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI8quR8qbqVz"
      },
      "source": [
        "class Logs():\n",
        "  def __init__(self,types):\n",
        "    self.logs = []\n",
        "    self.types = []\n",
        "    self.counter = 0\n",
        "    self.output_dir = []\n",
        "    for t,it in zip(types,np.arange(len(types))):\n",
        "      print(t)\n",
        "      self.types.append(t)\n",
        "      self.logs.append([])\n",
        "      self.output_dir.append(\"pictures/\" + t[1] + \"/\")\n",
        "      self.mkdir_p(self.output_dir[it])\n",
        "  \n",
        "  def find_division(self,x):\n",
        "    res = [1,x]\n",
        "    for i in range(2,int(np.floor(np.sqrt(x))+1)):\n",
        "      if x % i == 0:\n",
        "        res = [int(i),int(x/i)]\n",
        "    res = [int(np.ceil(x/3)),3]\n",
        "    return res\n",
        "\n",
        "  def log(self,values):\n",
        "    for value,typee,it in zip(values,self.types,np.arange(len(self.types))):\n",
        "      if typee[0] == 'number':\n",
        "        self.logs[it].append(value)\n",
        "      if typee[0] == 'matrix' or typee[0] == 'population':\n",
        "        if typee[0] == 'matrix':\n",
        "          value = cp.asnumpy(value) - np.diag(np.ones(value.shape[0]))\n",
        "        self.logs[it] = cp.asnumpy(value)\n",
        "      if typee[0] == 'vector':\n",
        "        self.logs[it] = cp.asnumpy(value)\n",
        "\n",
        "  def mkdir_p(self,mypath):\n",
        "    '''Creates a directory. equivalent to using mkdir -p on the command line'''\n",
        "\n",
        "    from errno import EEXIST\n",
        "    from os import makedirs,path\n",
        "\n",
        "    try:\n",
        "        makedirs(mypath)\n",
        "    except OSError as exc: # Python >2.5\n",
        "        if exc.errno == EEXIST and path.isdir(mypath):\n",
        "            pass\n",
        "        else: raise\n",
        "\n",
        "  def plot(self):\n",
        "    clear_output()\n",
        "    #sizes = self.find_division(len(self.types))\n",
        "    #fig, axes = plt.subplots(sizes[0],sizes[1], figsize = (24,14)) #maybe calculate figsize?\n",
        "    for log,it in zip(self.types,np.arange(len(self.types))):\n",
        "      #idx = (int(np.floor(it/sizes[1])),int(it%sizes[1]))\n",
        "      fig = plt.figure(figsize = (24,20))\n",
        "      ax = fig.add_subplot(111)\n",
        "      if log[0] == 'number':\n",
        "        ax.plot(np.arange(len(self.logs[it])),self.logs[it])\n",
        "        #axes[idx[0]][idx[1]].plot(np.arange(len(self.logs[it])),self.logs[it])\n",
        "        #axes[idx[0]][idx[1]].grid(True)\n",
        "        #axes[idx[0]][idx[1]].set_title(log[1] + ':')\n",
        "      if log[0] == 'matrix':\n",
        "        cax = ax.matshow(self.logs[it])\n",
        "        fig.colorbar(cax)\n",
        "        #cax = axes[idx[0]][idx[1]].matshow(self.logs[it])\n",
        "        #fig.colorbar(cax)\n",
        "        #axes[idx[0]][idx[1]].grid(True)\n",
        "        #axes[idx[0]][idx[1]].set_title(log[1] + ':')\n",
        "      if log[0] == 'population':\n",
        "        ax.scatter(np.arange(self.logs[it].shape[1]),np.mean(self.logs[it],axis=0))\n",
        "        #axes[idx[0]][idx[1]].scatter(np.arange(self.logs[it].shape[1]),np.mean(self.logs[it],axis=0))\n",
        "        #axes[idx[0]][idx[1]].grid(True)\n",
        "        #axes[idx[0]][idx[1]].set_title(log[1] + ':')\n",
        "      if log[0] == 'vector':\n",
        "        ax.scatter(np.arange(self.logs[it].shape[0]),self.logs[it])\n",
        "        #axes[idx[0]][idx[1]].scatter(np.arange(self.logs[it].shape[0]),self.logs[it])\n",
        "        #axes[idx[0]][idx[1]].grid(True)\n",
        "        #axes[idx[0]][idx[1]].set_title(log[1] + ':')\n",
        "      ax.set_title(log[1] + ':',fontsize = 15)\n",
        "      fig.savefig(self.output_dir[it] + log[1] + str(self.counter))\n",
        "      plt.show()\n",
        "    self.counter += 1\n",
        "    #fig.tight_layout()\n",
        "    #plt.show()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llmQDiFlwQui"
      },
      "source": [
        "POPULATION_SIZE = 128\n",
        "#input size do zmiany\n",
        "population = Neural_Network(POPULATION_SIZE,  (28*28, 1, 1), [['linear', 10, [1.,1.]]])\n",
        "sigmas = Sigmas_Neural_Network(POPULATION_SIZE,  (28*28, 1, 1), [['linear', 10, [1.,1.]]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZOmRD_nICsz"
      },
      "source": [
        "classifier = CMA_ES(population, .5, evaluate_population)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2dgy2JkII5_"
      },
      "source": [
        "classifier.fit(train_ds_mnist, 64, 128, 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzXUdH8rBPjf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}