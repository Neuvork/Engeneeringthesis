{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "results.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nozuaK3_CKjw"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Neuvork/Engeneering-thesis/blob/master/results.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5jcZnINFcRT"
      },
      "source": [
        "! git clone https://<username>:<password>@github.com/Neuvork/Engeneeringthesis.git --single-branch --branch cmaes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQIf2yvLB9pn"
      },
      "source": [
        "#DOPISAC CMA\n",
        "#ZROBIC REKURENCYJNY ES\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.linalg import sqrtm\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import copy\n",
        "import cupy as cp\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from Engeneeringthesis.sigmas import Sigmas_Neural_Network\n",
        "from Engeneeringthesis.NeuralNetwork import Neural_Network\n",
        "from Engeneeringthesis.Cma_es import CMA_ES\n",
        "from Engeneeringthesis.Logs import Logs\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl9rVITDlQyH"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU0va8DSXlK5"
      },
      "source": [
        "mempool = cp.get_default_memory_pool()\n",
        "pinned_mempool = cp.get_default_pinned_memory_pool()\n",
        "def cuda_memory_clear():\n",
        "    mempool.free_all_blocks()\n",
        "    pinned_mempool.free_all_blocks()          "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGdtEleAayvp"
      },
      "source": [
        "no_debug = 1\n",
        "basic_debug_mode = 2\n",
        "super_debug_mode = 3\n",
        "only_interesting = 5\n",
        "DEBUG_MODE = only_interesting"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6SmN-lZSUu_"
      },
      "source": [
        "train_ds_mnist = tfds.load(\"mnist\", split = \"train\", shuffle_files=True, batch_size=-1)\n",
        "test_ds_mnist = tfds.load(\"mnist\", split = \"test\", shuffle_files=True, batch_size=-1)\n",
        "\n",
        "train_ds_mnist = tfds.as_numpy(train_ds_mnist)\n",
        "test_ds_mnist = tfds.as_numpy(test_ds_mnist)\n",
        "\n",
        "train_ds_mnist = {\"image\" : cp.array(train_ds_mnist[\"image\"]/255., dtype=cp.float32), \"label\" : cp.array(train_ds_mnist[\"label\"]) }\n",
        "test_ds_mnist = {\"image\" : cp.array(test_ds_mnist[\"image\"]/255., dtype=cp.float32), \"label\" : cp.array(test_ds_mnist[\"label\"]) }"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i2VqaIb-Wyh"
      },
      "source": [
        "def evaluate_population(population, train_ds):\n",
        "    create_input_time = 0\n",
        "    preds_time = 0\n",
        "    points_count_time = 0\n",
        "    j  = 0\n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"___EVALUATE_POPULATION_START\")\n",
        "    #scores = np.zeros(population.layers[0][1].shape[0], dtype = np.uint32)\n",
        "    scores = cp.zeros(population.population_size, dtype = cp.uint32)\n",
        "    for image, label in zip(cp.array(train_ds['image']), cp.array(train_ds['label'])):\n",
        "        start = time.time()\n",
        "        image = image.flatten()\n",
        "        create_input_time += time.time() - start\n",
        "        start = time.time()\n",
        "        preds = population.forward(image)\n",
        "        preds_time += time.time() - start\n",
        "        start = time.time()\n",
        "        #scores += cp.asnumpy(preds == label)\n",
        "        scores += preds == label\n",
        "        points_count_time += time.time() - start\n",
        "        j += 1\n",
        "      \n",
        "    if DEBUG_MODE % basic_debug_mode == 0:\n",
        "      print(\"___EVALUATE_POPULATION_STOP\", \"create_input_time: \", create_input_time, \"preds_time:\", preds_time,\n",
        "          \"points_count_time: \", points_count_time, \"\\n best result: \", np.max(cp.asnumpy( scores)),\n",
        "          \"mean socre: \", np.mean(cp.asnumpy( scores)), \"min score: \", np.min(cp.asnumpy( scores))) \n",
        "    if DEBUG_MODE % only_interesting == 0:\n",
        "      print(\"best result: \", np.max(cp.asnumpy( scores)), \"mean socre: \", np.mean(cp.asnumpy( scores)), \"min score: \", np.min(cp.asnumpy( scores)))\n",
        "\n",
        "    return scores"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC4DvHDvSbyJ"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kysKh3qG1ra1"
      },
      "source": [
        "def custom_plot(ax, data):\n",
        "  XD = np.array([1,2,3,4,5])\n",
        "  ax.plot(XD)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i-Agjvi1qPv"
      },
      "source": [
        "logs = Logs([('matrix','covariance'),('vector','sigma'),\n",
        "                      ('vector','isotropic'),('vector','anisotropic'),('vector','mean'),\n",
        "                      ('number','best-score')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W7izOuOAWM4"
      },
      "source": [
        "class Caged_CMA_ES():\n",
        "  def __init__(self,population,sigma,evaluate_func, logs, number_of_cages, dimensionalities):\n",
        "    self.cages = []\n",
        "    self.logs = logs\n",
        "    self.number_of_cages = number_of_cages\n",
        "    self.population = population\n",
        "    self.dimensionalities = dimensionalities\n",
        "    self.evaluate_func = evaluate_func\n",
        "    for i in range(number_of_cages):\n",
        "      self.cages.append(CMA_ES(population, sigma, evaluate_func, logs, dimensionalities[i], i))\n",
        "\n",
        "     \n",
        "  def set_mean_act(self):\n",
        "    ret_mean_act = []\n",
        "    for i in range(number_of_cages):\n",
        "      ret_mean_act.append(cp.zeros(self.dimensionalities[i], dtype = cp.float32))\n",
        "    return ret_mean_act\n",
        "\n",
        "  def update_mean(self, scores,sorted_indices,mu):\n",
        "    ret_list = []\n",
        "    for i in range(number_of_cages):\n",
        "      ret_list.append(self.cages[i].update_mean(scores,sorted_indices,mu))\n",
        "    return ret_list\n",
        "    \n",
        "\n",
        "  def set_cs(self):\n",
        "    ret_list = []\n",
        "    for i in range(self.number_of_cages):\n",
        "      ret_list.append(0)\n",
        "    return ret_list\n",
        "\n",
        "  def find_division(self, number):\n",
        "    for i in range(int(np.sqrt(number)), 2, -1):\n",
        "      if number % i == 0:\n",
        "        return (i , number // i)\n",
        "      \n",
        "\n",
        "  def parse_log_args(self, mean_act, scores):\n",
        "    horizontal_stacks = []\n",
        "    horizontal, vertical = self.find_division(self.number_of_cages)\n",
        "    for i in range(vertical):\n",
        "      horizontal_stacks.append(np.array(cp.asnumpy(self.cages[i*horizontal].covariance_matrix)))\n",
        "      for j in range(1, horizontal):\n",
        "        horizontal_stacks[i] = np.hstack((horizontal_stacks[i], cp.asnumpy(self.cages[i*j + j].covariance_matrix)))\n",
        "    \n",
        "    cov = horizontal_stacks[0]\n",
        "    for i in range(1, vertical):\n",
        "      cov = np.vstack((cov, horizontal_stacks[i]))\n",
        "    \n",
        "    sigmas = []\n",
        "    for i in range(self.number_of_cages):\n",
        "      sigmas.append(self.cages[i].sigma)\n",
        "    sigmas = np.array(sigmas)\n",
        "\n",
        "    isotropic = np.array([])\n",
        "    anisotropic = np.array([])\n",
        "    for i in range(self.number_of_cages):\n",
        "      isotropic = np.concatenate((isotropic, cp.asnumpy(self.cages[i].isotropic)))\n",
        "      anisotropic = np.concatenate((anisotropic, cp.asnumpy(self.cages[i].anisotropic)))\n",
        "\n",
        "    mean = np.array([])\n",
        "    for i in range(self.number_of_cages):\n",
        "      mean = np.concatenate((mean, cp.asnumpy(mean_act[i])))\n",
        "    return [cov, sigmas, isotropic, anisotropic, mean, cp.max(scores)]\n",
        "\n",
        "\n",
        "  def fit(self, data, mu, lam, iterations): # mu is how many best samples from population, lam is how much we generate\n",
        "    for i in range(self.number_of_cages):\n",
        "      self.cages[i].weights = cp.log(mu+1/2) - cp.log(cp.arange(1,mu+1))\n",
        "      self.cages[i].weights = self.cages[i].weights/cp.sum(self.cages[i].weights)\n",
        "\n",
        "    \n",
        "    mu_w = 1/cp.sum(self.cages[0].weights**2)\n",
        "    \n",
        "    c_1, c_sigma, d_sigma, c_covariance, c_mu = np.zeros(self.number_of_cages), np.zeros(self.number_of_cages), np.zeros(self.number_of_cages), np.zeros(self.number_of_cages), np.zeros(self.number_of_cages)\n",
        "\n",
        "    alpha = 1.5\n",
        "    for i in range(self.number_of_cages):\n",
        "      c_1[i] = 2/(self.dimensionalities[i]**2)\n",
        "      c_sigma[i] = (mu_w + 2)/(self.dimensionalities[i] + mu_w + 5)\n",
        "      d_sigma[i] = 1 + 2*max([0,cp.sqrt((mu_w - 1)/(self.dimensionalities[i] + 1)) - 1]) + c_sigma[i] #dampening parameter could probably be hyperparameter, wiki says it is close to 1 so whatever\n",
        "      c_covariance[i] = (4 + mu_w/self.dimensionalities[i])/(self.dimensionalities[i] + 4 + 2*mu_w/self.dimensionalities[i]) # c_covariance * 100 not working\n",
        "      c_mu[i] = min([1-c_1[i],2*(mu_w - 2 + 1/mu_w)/(((self.dimensionalities[i]+2)**2)+mu_w)])\n",
        "      \n",
        "      \n",
        "    \n",
        "    \n",
        "    mean_act = self.set_mean_act()\n",
        "    mean_prev = self.set_mean_act()\n",
        "    c_s = self.set_cs()\n",
        "\n",
        "    file = open(\"PARAMS.txt\", \"w\")\n",
        "    file.write(\"c_1: \" + str(c_1) + \"\\n \\n\")\n",
        "    file.write(\"c_mu: \" + str(c_mu) + \"\\n\")\n",
        "    file.write(\"c_sigma: \" + str(c_sigma) + \"\\n \\n\")\n",
        "    file.write(\"d_sigma: \" + str(d_sigma) + \"\\n \\n\")\n",
        "    file.write(\"c_covariance: \" + str(c_covariance) + \"\\n\")\n",
        "    file.close()\n",
        "\n",
        "    #body \n",
        "    for i in range(iterations):\n",
        "      scores = self.evaluate_func(self.population, data)\n",
        "      print(cp.max(scores))\n",
        "      sorted_indices = cp.argsort(-scores)\n",
        "      for j in range(len(mean_prev)):\n",
        "        mean_prev[j] = mean_act[j].copy() #maybe deepcopy\n",
        "      self.population.parse_to_vector()\n",
        "      mean_act = self.update_mean(scores,sorted_indices,mu) #we need to be vectorized here\n",
        "      self.logs.log(self.parse_log_args(mean_act, scores))\n",
        "      self.logs.plot()\n",
        "      for j in range(self.number_of_cages):\n",
        "        self.cages[j].update_isotropic(mean_act[j],mean_prev[j],c_sigma[j],mu_w)\n",
        "        c_s[j] = self.cages[j].compute_cs(alpha,c_1[j],c_covariance[j])\n",
        "        self.cages[j].update_anisotropic(mean_act[j],mean_prev[j],mu_w,c_covariance[j],alpha)\n",
        "        self.cages[j].update_covariance_matrix(c_1[j],c_mu[j],c_s[j],scores,sorted_indices,mu,mean_prev[j])\n",
        "        self.cages[j].update_sigma(c_sigma[j],d_sigma[j])\n",
        "      \n",
        "      covariances = []\n",
        "      sigmas = []\n",
        "      for j in range(self.number_of_cages):\n",
        "        covariances.append(self.cages[j].covariance_matrix)\n",
        "        sigmas.append(self.cages[j].sigma)\n",
        "      self.population.caged_sample(covariances, sigmas, mean_act, lam)\n",
        "      covariances = []\n",
        "      sigams = []\n",
        "      \n",
        "      self.population.parse_from_vectors()\n",
        "    return self.population"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qsiN7jKQG7E"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G-io99VNezd"
      },
      "source": [
        "dimensionalities = []\n",
        "for i in range(784):\n",
        "  dimensionalities.append(10)\n",
        "number_of_cages = 784"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2R8qHtuQd1A"
      },
      "source": [
        "POPULATION_SIZE = 256\n",
        "#input size do zmiany\n",
        "population = Neural_Network(POPULATION_SIZE,  (28*28, 1, 1), [['linear', 10, [1.,1.]]], cage_dimensionalities=np.array(dimensionalities))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZOmRD_nICsz"
      },
      "source": [
        "classifier = Caged_CMA_ES(population, .5, evaluate_population, logs, number_of_cages, dimensionalities)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2dgy2JkII5_"
      },
      "source": [
        "classifier.fit(train_ds_mnist, 128, 256, 500)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}